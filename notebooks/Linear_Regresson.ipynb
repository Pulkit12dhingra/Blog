{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c789162e",
   "metadata": {},
   "source": [
    "In this notebook well test how Gradient Descent impacts the results of our previous regression approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2132ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (20640, 8)\n",
      "Target shape: (20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Step 1: Load dataset\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "print(\"Data shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41222e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (16512, 8)\n",
      "Testing data shape: (4128, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 2: Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8ff13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16512, 8), (4128, 8), (16512,), (4128,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reviewing our dataset\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00453243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's bring in scaling into the picture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 3: Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aff3b1",
   "metadata": {},
   "source": [
    "Using Sklearn's model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb0b2c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.550598777585777\n",
      "R^2 Score: 0.5798267665069695\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# 4. Fit SGDRegressor\n",
    "model = SGDRegressor(max_iter=1000, eta0=0.01, learning_rate='invscaling', penalty='l2', random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 5. Predict\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Step 7: Evaluate sklearn model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04b59d7",
   "metadata": {},
   "source": [
    "# From Scratch\n",
    "Let's try to code the algorithm from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11aa692f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.5659752078049892\n",
      "R^2 Score: 0.5680926968580774\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# -------------------------------\n",
    "# Compute Mean Squared Error loss with L2 regularization\n",
    "# -------------------------------\n",
    "def compute_loss(X, y, w, b, alpha):\n",
    "    # Predict outputs with current weights and bias\n",
    "    y_pred = X.dot(w) + b\n",
    "    # Compute Mean Squared Error (MSE)\n",
    "    mse = np.mean((y - y_pred) ** 2)\n",
    "    # Compute L2 penalty (Ridge regularization)\n",
    "    reg = alpha * np.sum(w ** 2)\n",
    "    # Return combined loss\n",
    "    return 0.5 * (mse + reg)\n",
    "\n",
    "# -------------------------------\n",
    "# Train linear regression model using Mini-Batch Stochastic Gradient Descent\n",
    "# -------------------------------\n",
    "def train_sgd_regressor(X, y, max_iter=100, batch_size=32, eta0=0.01, alpha=0.0001, power_t=0.25, learning_rate='invscaling'):\n",
    "    # Get number of samples (m) and features (n)\n",
    "    m, n = X.shape\n",
    "    # Initialize weights randomly (n x 1)\n",
    "    w = np.random.randn(n, 1)\n",
    "    # Initialize bias to zero\n",
    "    b = 0.0\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in range(max_iter):\n",
    "        # Shuffle the dataset at the beginning of each epoch\n",
    "        indices = np.random.permutation(m)\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "\n",
    "        # Loop over mini-batches\n",
    "        for start in range(0, m, batch_size):\n",
    "            end = start + batch_size\n",
    "            # Get current mini-batch of features and targets\n",
    "            xb = X_shuffled[start:end]\n",
    "            yb = y_shuffled[start:end].reshape(-1, 1)  # Ensure column vector\n",
    "\n",
    "            # Forward pass: predict outputs\n",
    "            y_pred = xb.dot(w) + b\n",
    "            # Compute prediction error\n",
    "            error = y_pred - yb\n",
    "\n",
    "            # Compute learning rate using inverse scaling schedule\n",
    "            t = epoch * (m // batch_size) + (start // batch_size) + 1  # Step count\n",
    "            eta = eta0 / (t ** power_t) if learning_rate == 'invscaling' else eta0\n",
    "\n",
    "            # Compute gradient for weights and bias (with L2 regularization)\n",
    "            grad_w = xb.T.dot(error) / len(xb) + alpha * w\n",
    "            grad_b = np.mean(error)\n",
    "\n",
    "            # Update weights and bias\n",
    "            w -= eta * grad_w\n",
    "            b -= eta * grad_b\n",
    "\n",
    "    # Return the final learned weights and bias\n",
    "    return w, b\n",
    "\n",
    "# -------------------------------\n",
    "# Predict using learned linear model\n",
    "# -------------------------------\n",
    "def predict(X, w, b):\n",
    "    # Compute and return predictions\n",
    "    return X.dot(w) + b\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Train the custom SGD model\n",
    "# -------------------------------\n",
    "w, b = train_sgd_regressor(\n",
    "    X_train_scaled, y_train,   # Scaled training data\n",
    "    max_iter=100,              # Number of epochs\n",
    "    batch_size=64,             # Mini-batch size\n",
    "    eta0=0.01,                 # Initial learning rate\n",
    "    alpha=0.0001,              # L2 regularization strength\n",
    "    learning_rate='invscaling' # Learning rate schedule\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Make predictions and evaluate model\n",
    "# -------------------------------\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = predict(X_test_scaled, w, b)\n",
    "\n",
    "# Evaluate using Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e97e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
