<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Byte-Sized-Brilliance-AI</title>
  <link rel="icon" type="image/png" href="../img/icon.png" />

  <!-- Open Graph -->
  <meta property="og:title" content="Pulkit's Blog" />
  <meta property="og:description" content="Explore tutorials, projects, and insights into AI, coding, and more." />
  <meta property="og:image" content="../img/social-preview.jpg" />
  <meta property="og:type" content="website" />

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Pulkit's Blog" />
  <meta name="twitter:description" content="Explore tutorials, projects, and insights into AI, coding, and more." />
  <meta name="twitter:image" content="../img/social-preview.jpg" />

  <!-- Bootstrap CSS -->
  <link
    href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css"
    rel="stylesheet"
  />
  <!-- Bootstrap Icons -->
  <link
    href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.5/font/bootstrap-icons.css"
    rel="stylesheet"
  />

  <link rel="stylesheet" href="data/style.css?v=1.0.0" />
  <link
    href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css"
    rel="stylesheet"
  />
</head>
<body>
  <div class="container mt-4">
    <div class="d-flex flex-column flex-md-row justify-content-between align-items-start align-items-md-center mb-4">
      <h2 class="fw-bold mb-3">LangChain + Ollama: Your Gateway to LLM Apps, Explained with Code üí°</h2>
      <a href="../index.html" class="btn btn-primary">‚Üê Back to Home</a>
    </div>
    <p class="text-muted">Published: <span id="publish-date">May 8, 2025</span></p>
    <hr />
    <p><strong>üëâ New to Ollama?</strong> Before diving in, make sure you‚Äôve got it set up locally. Follow this guide first:  
        <a href="https://pulkit12dhingra.github.io/Blog/content/Blog_8.html" target="_blank">
          How to Setup Ollama on Your Machine üöÄ
        </a>
      </p>
    <p>LangChain is a powerful framework that simplifies the development of applications powered by large language models (LLMs). Whether you're building agents, chatbots, or assistants, LangChain gives you building blocks for <strong>development</strong>, <strong>monitoring</strong>, and <strong>deployment</strong>.</p>

    <h4>üß† Why LangChain?</h4>
    <p>LangChain simplifies every stage of the LLM application lifecycle:</p>
    <ul>
      <li><strong>Development:</strong> Build apps with open-source components, or create stateful agents using <code>LangGraph</code>.</li>
      <li><strong>Productionization:</strong> Track and optimize performance with <code>LangSmith</code>.</li>
      <li><strong>Deployment:</strong> Turn prototypes into APIs and assistants using the <code>LangGraph Platform</code>.</li>
    </ul>

    <div class="text-center mb-4">
        <img src="../img/Blog_9_1.png" alt="LangChain Logo" class="img-fluid rounded shadow" style="max-width: 400px; width: 100%; height: auto;" />
      </div>
      

    <h4>üõ†Ô∏è Two Ways to Use the Ollama Model</h4>
    <p>LangChain supports Ollama models ‚Äî and there are two primary interfaces depending on your use case.</p>

    <h5>üß™ Option 1: Plain Completion</h5>
    <pre class="bg-light p-3 rounded"><code>from langchain.llms import Ollama

llm = Ollama(model="gemma3")
response = llm("What is the capital of France?")
print(response)</code></pre>
<div class="mb-4">
    <img src="../img/Blog_9_2.png" alt="LangChain Logo" class="img-fluid rounded shadow" style="max-width: 400px; width: 100%; height: auto;" />
  </div>
  

    <h5>üí¨ Option 2: Chat Interface</h5>
    <pre class="bg-light p-3 rounded"><code>from langchain_community.chat_models import ChatOllama

model = ChatOllama(model="gemma3")
model.invoke("Hello, world!")</code></pre>
<div class="mb-4">
    <img src="../img/Blog_9_3.png" alt="LangChain Logo" class="img-fluid rounded shadow" style="max-width: 400px; width: 100%; height: auto;" />
  </div>
    <h4>ü§î Ollama vs. ChatOllama ‚Äî What's the Difference?</h4>
    <div class="table-responsive">
      <table class="table table-bordered table-striped">
        <thead class="table-dark">
          <tr>
            <th>Feature / Use Case</th>
            <th><code>Ollama</code> (`langchain.llms`)</th>
            <th><code>ChatOllama</code> (`langchain_community.chat_models`)</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>Input</td><td>Text string</td><td>Message objects (e.g., HumanMessage)</td></tr>
          <tr><td>Output</td><td>Text completion</td><td>Chat message (.content)</td></tr>
          <tr><td>Roles</td><td>‚ùå Not supported</td><td>‚úÖ Supported (system, user, assistant)</td></tr>
          <tr><td>Best For</td><td>One-shot prompts</td><td>Multi-turn chat, assistants</td></tr>
          <tr><td>Integrations</td><td>PromptTemplate, LLMChain</td><td>ChatPromptTemplate, ChatChain</td></tr>
        </tbody>
      </table>
    </div>

    <h4>üí¨ Using Chat Messages</h4>
    <pre class="bg-light p-3 rounded"><code>from langchain_community.chat_models import ChatOllama
from langchain_core.messages import HumanMessage, SystemMessage

model = ChatOllama(model="gemma3")

messages = [
    SystemMessage("Provide all the responses with a pun at the end"),
    HumanMessage("It is a wonderful day!!"),
]

model.invoke(messages)</code></pre>
    <div class="mb-4">
        <img src="../img/Blog_9_4.png" alt="Chat" class="img-fluid rounded shadow" style="max-width: 400px; width: 100%; height: auto;" />
    </div>
    <p>You can also use streaming to output tokens:</p>
    <pre class="bg-light p-3 rounded"><code>for token in model.stream(messages):
    print(token.content, end="|")</code></pre>

    <h4>üß± Prompt Templates: The Real Superpower</h4>
    <p>Prompt templates modularize input to LLMs and come in two main forms:</p>

    <h5>‚úèÔ∏è String PromptTemplate</h5>
    <pre class="bg-light p-3 rounded"><code>from langchain_core.prompts import PromptTemplate

prompt_template = PromptTemplate.from_template("Tell me a joke about {topic}")
prompt = prompt_template.invoke({"topic": "Newton"})
model.invoke(prompt)</code></pre>

    <h5>üí¨ ChatPromptTemplate</h5>
    <pre class="bg-light p-3 rounded"><code>from langchain_core.prompts import ChatPromptTemplate

prompt_template = ChatPromptTemplate([
    ("system", "You are a comedian"),
    ("user", "Tell me a joke about {topic}")
])

prompt = prompt_template.invoke({"topic": "Newton"})
response = model.invoke(prompt)
print(response.content)</code></pre>
    <div class="mb-4">
        <img src="../img/Blog_9_5.png" alt="Chat" class="img-fluid rounded shadow" style="max-width: 400px; width: 100%; height: auto;" />
    </div>
    <h5>üîÅ MessagesPlaceholder (Dynamic Insertion)</h5>
    <pre class="bg-light p-3 rounded"><code>from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage

prompt_template = ChatPromptTemplate([
    ("system", "You are a helpful assistant"),
    MessagesPlaceholder("msgs")
])

prompt = prompt_template.invoke({
    "msgs": [
        HumanMessage("hi!"),
        HumanMessage("Tell Me a Joke about Newton"),
        HumanMessage("Tell Me a Joke about Tesla")
    ]
})

response = model.invoke(prompt)
print(response.content)</code></pre>
<div class="mb-4">
    <img src="../img/Blog_9_6.png" alt="Chat" class="img-fluid rounded shadow" style="max-width: 400px; width: 100%; height: auto;" />
</div>
    <h4>‚úÖ Final Thoughts</h4>
    <p>LangChain isn‚Äôt just another Python wrapper ‚Äî it's a modular, scalable toolkit for building full-fledged LLM-powered applications. With Ollama support, you can even run models locally. Whether you‚Äôre exploring prompt templates or building conversational agents, LangChain makes the process simple and production-ready.</p>
  </div>
</body>
</html>
